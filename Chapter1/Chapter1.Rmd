---
title: "Chapter 1"
output: html_notebook
---

```{r setup}
knitr::opts_knit$set(root.dir = '~/Documents/Linear-Model-using-R')
```

# Chapter 1 Introduction 

## 1.1 Before you start

## 1.2 Initial Data Analysis

```{r}
# install.packages("faraway")
library(faraway)
```
### import the dataset and have a first look at it

```{r}
# import the dataset called `pima` from the package
data(pima, package="faraway")
head(pima)
```

```{r}
# alternative way to import data
# makes all data and functions that are included in the package available
require(faraway)
head(pima)
```

### make numerical summaries

At this stage, we are looking for anything unusual or unexpected
e.g. data-entry error

```{r}
# obtain numerical summaries
# summary function gives the usual univariate summary information 
summary(pima)
```

We first look at the maximum value in variable `pregnant`: 17 months is not impossible although highly unlikely. 

The 0 values in `diastolic` should not be correct as it means no blood pressure. (During the data analysis part, we need to have basic domain knowledge on the area or some common sense) So, we need to further investigate the variable by sorting them:

```{r}
sort(pima$diastolic)
```

From the data, it is obvious that 35 entries have value 0, which probably indicates that these 0s are used to indicate missing values. If we don't change the correct form for these missing values, these values may affect the analysis. So, we can convert these 0s to NA inferring that these values are missing.

Thus, we set all 0s in `diastolic`, `glucose`, `triceps`, `insulin` and `bmi` to NA.

```{r}
# convert all the 0 values in 5 variables to NA
pima$diastolic[pima$diastolic==0] <- NA
pima$glucose[pima$glucose == 0] <- NA
pima$triceps[pima$triceps == 0] <- NA
pima$insulin[pima$insulin == 0] <- NA
pima$bmi[pima$bmi == 0] <- NA
```

Variable `test` is a categorical variable which means it is a `factor` variable.

```{r}
# convert the `test` variable to a factor variable; otherwise, this variable will be treated as a 
# quantitative variable
pima$test <- factor(pima$test)
# give a summary table for test variable
summary(pima$test)
```

We can convert the labels for factor variables to descriptive ones:

```{r}
#convert the levels of `test` variable to descriptive labels
levels(pima$test) <- c("negative","positive")
summary(pima)
```

### graphic descriptions

```{r}
#histogram with bins specified by r
hist(pima$diastolic, xlab="diastolic",main="")
```

```{r}
# kernel estimate(density plot) of histogram
plot(density(pima$diastolic, na.rm = T),main="")
```

```{r}
plot(sort(pima$diastolic),ylab="Sorted Diastolic")
```

```{r}
# plot a scatterplot for diabetes against diastolic with the dataset pima
plot(diabetes~diastolic,pima)
```

```{r}
# plot two boxplots for diabetes against both positive and negative cases
plot(diabetes~test,pima)
```

```{r}
# install.packages("ggplot2")
require(ggplot2)
```

```{r}
# histogram
ggplot(pima, aes(x=diastolic))+geom_histogram()
```

```{r}
# kernel estimate(density plot)
ggplot(pima, aes(x=diastolic))+geom_density()
```

```{r}
# scatterplot
ggplot(pima, aes(x=diastolic,y=diabetes))+geom_point()
```

#### explanation of `ggplot`

`ggplot(<dataset_name>, aes(x = <x_axis>, y = <y_axis>, colour=<colour_name>, ...))+ <geo_plots()>+theme()+facet_grid()`

ggplot arguments:
    - dataset
    - aesthetic: specify x-axis, y-axis, shape of points, colour of graph, etc
    - geom_plots: different sorts of plots
    - theme: specify options on apperance of the plot
    - facet_grid: form a matrix of panels defined by row and column faceting variables

```{r}
# scatterplot with a legend on the top
ggplot(pima, aes(x=diastolic, y=diabetes, shape=test))+geom_point()+
    theme(legend.position="top", legend.direction="horizontal")
```

```{r}
# shape in aes function change the shape of points based on the values of test variable
ggplot(pima, aes(x=diastolic, y=diabetes, shape=test))+geom_point(size=1)+facet_grid(~test)
```

## 1.3 When to use linear models

Regression analysis have two main objectives:

1. prediction of future or unseen response given specified values of predictors.

2. Assessment of the effect of, or relations between, predictors and responses. If possible, we want to infer casual relationships.

## 1.4 History

### Use linear regression to find coefficients in physical science

```{r}
data(manilius, package="faraway")
head(manilius)
```

```{r}
lm1 <- lm(arc~sinang+cosang,data=manilius)
lm1$coef
```

### Use of linear regression to find coefficients in social science

```{r}
data(GaltonFamilies, package = "HistData")
head(GaltonFamilies)
```

```{r}
plot(childHeight~midparentHeight, GaltonFamilies)
```

```{r}
lm2 <- lm(childHeight~GaltonFamilies$midparentHeight,data=GaltonFamilies)
coef(lm2)
plot(childHeight~midparentHeight, GaltonFamilies)
abline(lm2)
```


## Exercises

